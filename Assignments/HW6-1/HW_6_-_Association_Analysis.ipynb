{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name(s): Ashley Yude (acy366) and Danica Padlan (dmp3357)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Association Analysis\n",
    "\n",
    "Association analysis uses machine learning to extract frequent itemsets and strong association rules from large datasets. In this assignment you'll be implementing one of the most commonly used algorithms for association rule mining - the Apriori algorithm.\n",
    "\n",
    "The dataset (`large_retail.txt`) that we are going to use has been adapted from the [Retail Market Basket Dataset](http://fimi.ua.ac.be/data/retail.pdf). This dataset contains transaction records supplied by a Belgian retail supermarket store. Each line in the file represents a separate transaction with the item ids separated by space. The dataset has 3000 transactions and 99 different item ids.\n",
    "\n",
    "You are also provided with a smaller dataset (`small_retail.txt`) with 9 transactions and 5 different item ids along with the solutions. You can test and debug your implementation on this smaller dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apriori Algorithm from scratch\n",
    "\n",
    "The Apriori algorithm is a classical algorithm in data mining. It is used for mining frequent itemsets and relevant association rules. In this part, you'll be implementing this algorithm for generating the itemsets that occur enough times to meet the `min_sup` threshold.\n",
    "\n",
    "**Implementation Hint:**\n",
    "\n",
    "- Use the `frozenset` data structure in Python, which is similar to `set` in functionality, to represent the itemsets, because `frozenset` is an immutable (hashable) data structure. You can maintain a dictionary that maps from the itemset (a `frozenset`) to its support count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports (you can add additional headers if you wish)\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the dataset from file\n",
    "def load_dataset(file_name):\n",
    "    with open(file_name, 'r') as f:\n",
    "        content = f.readlines()\n",
    "        data = [[int(x) for x in line.rstrip().split()] for line in content]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2, 5],\n",
       " [2, 4],\n",
       " [2, 3],\n",
       " [1, 2, 4],\n",
       " [1, 3],\n",
       " [2, 3],\n",
       " [1, 3],\n",
       " [1, 2, 3, 5],\n",
       " [1, 2, 3]]"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the small_retail dataset\n",
    "small_dataset = load_dataset('small_retail.txt')\n",
    "small_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1. Implement the function `create_1_itemsets` that takes as input the entire dataset and returns a list of all the candidate 1-itemsets. For example, for `small_retail.txt` it should return:\n",
    "~~~\n",
    "[frozenset({1}),\n",
    " frozenset({2}),\n",
    " frozenset({3}),\n",
    " frozenset({4}),\n",
    " frozenset({5})]\n",
    " ~~~\n",
    " Please don't hardcode the item ids, your code should support item ids that are non-sequential."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_1_itemsets(dataset):\n",
    "    unique = []\n",
    "    c1 = []\n",
    "    # your code goes here\n",
    "    \n",
    "    #double loop to find unique item numbers\n",
    "    for i in dataset:\n",
    "        for j in i:\n",
    "            \n",
    "            #check if item j is in the array,\n",
    "            #if not add to the initial list\n",
    "            if j not in unique: unique.append(j)\n",
    "    \n",
    "    #sort unique items list inorder\n",
    "    unique.sort()\n",
    "    \n",
    "    #loop to set each item into a frozen set\n",
    "    for i in unique:\n",
    "        \n",
    "        #create frozenset out of list with 1 object in it\n",
    "        temp = frozenset({i})\n",
    "        c1.append(temp)\n",
    "    \n",
    "    return c1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[frozenset({1}),\n",
       " frozenset({2}),\n",
       " frozenset({3}),\n",
       " frozenset({4}),\n",
       " frozenset({5})]"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Testing: works!\n",
    "sets = create_1_itemsets(small_dataset)\n",
    "sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2. Implement function `filter_candidates` that takes as input the candidate itemsets, the dataset, and the minumum support count `min_sup`, and filters out candidates that don't meet the support threshold.\n",
    "\n",
    "Return a list of all the itemsets that meet `min_sup` (as a list of frozensets) and the support count information for all of them (as a `dict`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_candidates(candidates, dataset, min_sup):\n",
    "    retlist = []\n",
    "    support_data = {}\n",
    "    # your code goes here\n",
    "    \n",
    "    #assuming candidate set list is items of one size\n",
    "    #double for loop to check through all candidates\n",
    "    for i in candidates:\n",
    "        \n",
    "        #convert frozen_set to list\n",
    "        cur_list = list(i)\n",
    "        value = 0\n",
    "        \n",
    "        #loop through all datasets\n",
    "        for j in dataset:\n",
    "            \n",
    "            if (all(x in j for x in cur_list)): value += 1\n",
    "    \n",
    "    \n",
    "        #check if total num of list that contain the cur_list, add to dictionary\n",
    "        if value >= min_sup:\n",
    "            retlist.append(i)\n",
    "            support_data.update({i: value})\n",
    "    \n",
    "    return retlist, support_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{frozenset({1}): 6, frozenset({2}): 7, frozenset({3}): 6, frozenset({4}): 2, frozenset({5}): 2}\n"
     ]
    }
   ],
   "source": [
    "#Testing: works!\n",
    "retlist, support_data = filter_candidates(sets, small_dataset, 2)\n",
    "print(support_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3. Implement the function `generate_next_itemsets` that takes in frequent itemsets of size `k` and generates candidate itemsets of size `k + 1`.\n",
    "\n",
    "Use either the F(k-1) x F(k-1) or the F(k-1) x F(1) candidate generation method, then **filter the candidate list based on the apriori principle before returning it.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_next_itemsets(freq_sets):\n",
    "    retlist = []\n",
    "    #loop through all ordered and freq item sets\n",
    "    for i in range(len(freq_sets)):\n",
    "        \n",
    "        #loop through i+1 range\n",
    "        for j in range(i + 1, len(freq_sets)):\n",
    "            list1 = list(freq_sets[i])\n",
    "            list2 = list(freq_sets[j])\n",
    "\n",
    "            #check if first k-1 items match\n",
    "            if( list1[0:len(list1)-1] ==  list2[0:len(list2)-1]):\n",
    "\n",
    "                #if last values aren't matching, combine into list, \n",
    "                #make them frozenset, and add to retlist\n",
    "                if((list1[len(list1)-1] != list2[len(list2)-1])):\n",
    "                   \n",
    "                    temp_list = list(set(list1).union(set(list2)))\n",
    "                    retlist.append(frozenset(temp_list))\n",
    "                 \n",
    "    #filter list based on apriori        \n",
    "    filtered_list = []\n",
    "    for x in retlist:\n",
    "        in_set = True\n",
    "        \n",
    "        #loop through all items\n",
    "        for i in range(len(x)):\n",
    "            # create all possible k-subsets of the candidate itemset\n",
    "            subset = list(x)[:i] + list(x)[i+1:]\n",
    "            if frozenset(subset) not in freq_sets:\n",
    "                in_set = False\n",
    "                break\n",
    "        if in_set: filtered_list.append(x)\n",
    "                \n",
    "    return filtered_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[frozenset({1, 2}), frozenset({1, 3}), frozenset({1, 4}), frozenset({1, 5}), frozenset({2, 3}), frozenset({2, 4}), frozenset({2, 5}), frozenset({3, 4}), frozenset({3, 5}), frozenset({4, 5})]\n"
     ]
    }
   ],
   "source": [
    "# Testing: initial works for min_thresh 2 (10 combos), 6 (3 combos), 7 (0 comboe)\n",
    "next_itemsets = generate_next_itemsets(retlist)\n",
    "print(next_itemsets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4. Implement the function `apriori_freq_itemsets` that takes the entire dataset as input and returns all the frequent itemsets that meet `min_sup`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apriori_freq_itemsets(dataset, minsup):\n",
    "    retlist = []\n",
    "    support_data = {}\n",
    "    more_cands = True\n",
    "    \n",
    "    #returns all frequent itemsets of all k sizes\n",
    "    #intially make 1-itemsets\n",
    "    cands = create_1_itemsets(dataset)\n",
    "    \n",
    "#   #loop til no more candidates found\n",
    "    while more_cands:\n",
    "    \n",
    "        #filter all candidates and get their support counts\n",
    "        filtered_cands, support_counts = filter_candidates(cands, dataset, minsup)\n",
    "        \n",
    "        retlist.append(filtered_cands)\n",
    "        support_data.update(support_counts)\n",
    "\n",
    "        cands = generate_next_itemsets(filtered_cands)\n",
    "        \n",
    "        if len(cands) <= 0:\n",
    "            more_cands = False\n",
    "    \n",
    "    # your code goes here\n",
    "    return retlist, support_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{frozenset({1}): 6,\n",
       " frozenset({2}): 7,\n",
       " frozenset({3}): 6,\n",
       " frozenset({4}): 2,\n",
       " frozenset({5}): 2,\n",
       " frozenset({1, 2}): 4,\n",
       " frozenset({1, 3}): 4,\n",
       " frozenset({1, 5}): 2,\n",
       " frozenset({2, 3}): 4,\n",
       " frozenset({2, 4}): 2,\n",
       " frozenset({2, 5}): 2,\n",
       " frozenset({1, 2, 3}): 2,\n",
       " frozenset({1, 2, 5}): 2}"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test\n",
    "freq_list, support_counts = apriori_freq_itemsets(small_dataset, 2)\n",
    "support_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5. Display the frequent item sets in the form of a table along with their `support` (as a fraction: support count over number of transactions) for the `large_retail.txt` dataset **with a min support count of 300**.\n",
    "\n",
    "Sample Table Format (tab separated table)\n",
    "\n",
    "~~~\n",
    "Sup     Freq Itemset\n",
    "0.67\t[1]\n",
    "0.44\t[1, 2]\n",
    "(and so on)\n",
    "...\n",
    "...\n",
    "~~~\n",
    "\n",
    "`support(itemset) = support_count(itemset) / num_total_transactions`.\n",
    "\n",
    "The `support` and the itemset should be separated by a tab (`'\\t'`).\n",
    "\n",
    "Note that the `support` should be rounded to the nearest 2 decimal places (use `round(sup, 2)`). If a support_fraction only contains 1 decimal place (for example, 0.1), you do not need to add a 0 to the end of it (leaving it as 0.1 is fine).\n",
    "\n",
    "The itemsets should also be in a sorted order where smaller itemsets should come before larger itemsets and itemsets of the same size should be sorted amongst themselves.\n",
    "\n",
    "For eg. \n",
    "~~~~\n",
    "[1, 2] should come before [1, 2, 3]\n",
    "[1, 2, 3] should come before [1, 2, 4]\n",
    "[1, 2, 3] should come before [1, 4, 5]\n",
    "[1, 2, 3] should come before [2, 3, 4]\n",
    "~~~~\n",
    "\n",
    "Note that **this order is very important for grading!** \n",
    "\n",
    "The output also shouldn't contain any duplicates. \n",
    "\n",
    "The sample output for the `small_retail.txt` dataset with `min_sup` set to 2 is:\n",
    "\n",
    "~~~~\n",
    "Sup     Freq Itemset\n",
    "0.67\t[1]\n",
    "0.78\t[2]\n",
    "0.67\t[3]\n",
    "0.22\t[4]\n",
    "0.22\t[5]\n",
    "0.44\t[1, 2]\n",
    "0.44\t[1, 3]\n",
    "0.22\t[1, 5]\n",
    "0.44\t[2, 3]\n",
    "0.22\t[2, 4]\n",
    "0.22\t[2, 5]\n",
    "0.22\t[1, 2, 3]\n",
    "0.22\t[1, 2, 5]\n",
    "~~~~\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_table(sup_count, total_transac):\n",
    "    print(\"Sup\\t Freq Itemset\")\n",
    "    for i in sup_count:\n",
    "        cur_support = sup_count.get(i) / total_transac\n",
    "        print(round(cur_support,2), \"\\t\", sorted(list(i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sup\t Freq Itemset\n",
      "0.1 \t [31]\n",
      "0.14 \t [32]\n",
      "0.11 \t [36]\n",
      "0.26 \t [38]\n",
      "0.53 \t [39]\n",
      "0.22 \t [41]\n",
      "0.47 \t [48]\n",
      "0.11 \t [60]\n",
      "0.11 \t [65]\n",
      "0.11 \t [89]\n",
      "0.14 \t [32, 39]\n",
      "0.15 \t [38, 39]\n",
      "0.13 \t [38, 48]\n",
      "0.14 \t [39, 41]\n",
      "0.33 \t [39, 48]\n",
      "0.18 \t [41, 48]\n",
      "0.14 \t [39, 41, 48]\n",
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "# Testing on small_retail.txt (IT WORKS)\n",
    "large_dataset = load_dataset('large_retail.txt')\n",
    "freq_list, large_support_counts = apriori_freq_itemsets(large_dataset, 300)\n",
    "print_table(large_support_counts, len(large_dataset))\n",
    "\n",
    "print(type(large_support_counts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q6. Find the closed frequent item sets. Display results for the `large_retail.txt` dataset in the same format as specified in Q5.\n",
    "\n",
    "The results for the `small_retail` dataset are as follows:\n",
    "\n",
    "~~~~\n",
    "Sup\tFreq Itemset\n",
    "0.0\t[1]\n",
    "0.0\t[2]\n",
    "0.0\t[3]\n",
    "0.0\t[1, 2]\n",
    "0.0\t[1, 3]\n",
    "0.0\t[2, 3]\n",
    "0.0\t[2, 4]\n",
    "0.0\t[1, 2, 3]\n",
    "0.0\t[1, 2, 5]\n",
    "~~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closed_freq_itemsets(support_data):\n",
    "\n",
    "    # Dictionary since we need to store support counts with the frequent items\n",
    "    closed_freq_sets = {}\n",
    "    # use to loop through closed set to find if curr is a superset\n",
    "    \n",
    "    #loop through all the keys in \n",
    "    for i, i_sup_counts in support_data.items():\n",
    "        \n",
    "        # Since support_data is always in order, it will never be a subset of anything in closed_freq_sets\n",
    "        #check if its a superset of anything else in the list\n",
    "        for j, j_sup_counts in list(closed_freq_sets.items()):\n",
    "            \n",
    "            if (set(j).issubset(set(i))):\n",
    "                \n",
    "                # if j has less counts than i, remove from closed list\n",
    "                if (j_sup_counts <= i_sup_counts):\n",
    "                    del closed_freq_sets[j]\n",
    "                    \n",
    "        # add current to closed_freq_sets\n",
    "        closed_freq_sets.update({i:support_data.get(i)})\n",
    "            \n",
    "                    \n",
    "    return closed_freq_sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "large dataset closed_freq_itemsets\n",
      "Sup\t Freq Itemset\n",
      "0.1 \t [31]\n",
      "0.11 \t [36]\n",
      "0.26 \t [38]\n",
      "0.53 \t [39]\n",
      "0.22 \t [41]\n",
      "0.47 \t [48]\n",
      "0.11 \t [60]\n",
      "0.11 \t [65]\n",
      "0.11 \t [89]\n",
      "0.14 \t [32, 39]\n",
      "0.15 \t [38, 39]\n",
      "0.13 \t [38, 48]\n",
      "0.33 \t [39, 48]\n",
      "0.18 \t [41, 48]\n",
      "0.14 \t [39, 41, 48]\n"
     ]
    }
   ],
   "source": [
    "#Testing with small_retail/dataset (IT WORKS)\n",
    "# closed = closed_freq_itemsets(support_counts)\n",
    "# print(\"small dataset closed_freq_itemsets\")\n",
    "# print_table(closed, len(small_dataset))\n",
    "\n",
    "#Testing with large\n",
    "large_closed = closed_freq_itemsets(large_support_counts)\n",
    "print(\"large dataset closed_freq_itemsets\")\n",
    "print_table(large_closed, len(large_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Credit (+5 points)\n",
    "\n",
    "Q7. Now, generate the strong rules from the frequent itemsets. Given a dictionary of frequent itemsets and their supports, generate all the rules having confidence above some provided `min_conf` threshold. Display the rules in the form of a table.\n",
    "\n",
    "Sample table format (tab separated table):\n",
    "\n",
    "~~~\n",
    "Sup     Conf    Rule\n",
    "0.44\t0.67\t[1] -> [2]\n",
    "0.22\t1.0\t [5] -> [1, 2]\n",
    "0.22\t1.0\t [2, 5] -> [1]\n",
    "(and so on)\n",
    "...\n",
    "...\n",
    "~~~\n",
    "\n",
    "Rule confidence should be rounded to the nearest 2 decimal places (use `round(conf, 2)`). This table should also be tab (`'\\t'`) separated. The rules should be displayed in a sorted order. If a rule is given as `LHS -> RHS` then the rules for which `len(LHS)` is lesser should appear first. If the `len(LHS)` is equal for two rules then rules for which `len(RHS)` is lesser should appear first. If both `len(LHS)` and `len(RHS)` is equal then the rules should be sorted based on LHS first and then based on RHS.\n",
    "\n",
    "~~~~\n",
    "Note:\n",
    "LHS (Left Hand Side)\n",
    "RHS (Right Hand Side)\n",
    "~~~~\n",
    "\n",
    "For eg.\n",
    "~~~~\n",
    "[3] -> [2] should come before [1, 3] -> [4]\n",
    "[4] -> [2] should come before [2] -> [3, 4]\n",
    "[1, 3] -> [2] should come before [1, 5] -> [2]\n",
    "[1, 2] -> [3] should come before [1, 2] -> [5]\n",
    "~~~~\n",
    "\n",
    "Note that **this order is important for grading**. \n",
    "\n",
    "The sample output for the `small_retail` dataset with `min_conf = 0.5` is:\n",
    "\n",
    "~~~~\n",
    "Sup\t Conf\tRule\n",
    "0.44\t0.67\t[1] -> [2]\n",
    "0.44\t0.67\t[1] -> [3]\n",
    "0.44\t0.57\t[2] -> [1]\n",
    "0.44\t0.57\t[2] -> [3]\n",
    "0.44\t0.67\t[3] -> [1]\n",
    "0.44\t0.67\t[3] -> [2]\n",
    "0.22\t1.0\t [4] -> [2]\n",
    "0.22\t1.0\t [5] -> [1]\n",
    "0.22\t1.0\t [5] -> [2]\n",
    "0.22\t1.0\t [5] -> [1, 2]\n",
    "0.22\t0.5\t [1, 2] -> [3]\n",
    "0.22\t0.5\t [1, 2] -> [5]\n",
    "0.22\t0.5\t [1, 3] -> [2]\n",
    "0.22\t1.0\t [1, 5] -> [2]\n",
    "0.22\t0.5\t [2, 3] -> [1]\n",
    "0.22\t1.0\t [2, 5] -> [1]\n",
    "~~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_table_with_rules(sup_count, total_transac, lhs, rhs, conf):\n",
    "    print(\"Sup\\t Conf\\t Rule\")\n",
    "    for i in sup_count:\n",
    "        cur_support = sup_count.get(i) / total_transac\n",
    "        print(round(cur_support,2), \"\\t\", conf[i], \"\\t\", lhs[i], \" -> \", rhs[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_rules(support_data, minconf):\n",
    "    pass\n",
    "    # your code goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lhs, rhs, conf = generate_rules(support_counts, 0.5)\n",
    "# print_table_with_rules(rules_sup_count, len(small_dataset), lhs, rhs, conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 - Association Analysis using MLXtend\n",
    "\n",
    "## Installation\n",
    "`scikit-learn` does not provide any functionality for association rule mining so for this assignment you will be using the `MLxtend` library. The documentation for this library is available [here](http://rasbt.github.io/mlxtend/).\n",
    "\n",
    "You will need to install the `MLxtend` library. There are several ways of doing this; you can follow the instructions below, or see the setup guide  [here](http://rasbt.github.io/mlxtend/installation/).\n",
    "\n",
    "\n",
    "### Conda\n",
    "\n",
    "If you downladed Anaconda in order to get Jupyter Notebooks (which is the most common way to get Jupyter Notebooks), then you will want to install `MLxtend` using Conda. \n",
    "\n",
    "Open a command prompt / terminal window and type:\n",
    "\n",
    "`conda install mlxtend --channel conda-forge`\n",
    "\n",
    "### PyPi\n",
    "\n",
    "You can also install via pip. \n",
    "Note: If you are running Jupyter notebooks through an Anaconda install, then pip may not place the `MLxtend` libraries in the correct place for use in Jupyter (which is why you should use Conda instead of pip, if you downloaded Anaconda).\n",
    "\n",
    "Open a command prompt / terminal window and type:\n",
    "\n",
    "`pip3 install mlxtend`\n",
    "\n",
    "### Google Colab\n",
    "\n",
    "If you are using Google Colab, you can install MLXtend via a pip install command with an exclamation point in front of it, in one of your notebook cells. The exclamation points allows you to put shell commands inside of Colab. \n",
    "\n",
    "In a cell in your Colab notebook, type:\n",
    "\n",
    "`!pip install mlxtend`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "For the second part of this assignment, the data we'll use comes from a bakery called \"The Bread Basket\", located in the historic center of Edinburgh. The dataset contains more than 9000 transactions from the bakery. The file contains the following columns:\n",
    "\n",
    "- Date. Categorical variable that tells us the date of the transactions (YYYY-MM-DD format). The column includes dates from 2016-10-30 to 2017-04-09.\n",
    "\n",
    "- Time. Categorical variable that tells us the time of the transactions (HH:MM:SS format).\n",
    "\n",
    "- Transaction. Quantitative variable that allows us to differentiate the transactions. The rows that share the same value in this field belong to the same transaction.\n",
    "\n",
    "- Item. Categorical variable with the products purchased.\n",
    "\n",
    "In this part, you'll be running the Apriori algorithm from the MLxtend library to generate the itemsets that occur more than the `min_sup` threshold. Based on these frequent itemsets, you'll find association rules that have confidence above the `min_conf` threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports (you can add additional headers if you wish)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import apriori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the dataset from file\n",
    "def load_dataset(file_name):\n",
    "    with open(file_name, 'r') as f:\n",
    "        content = f.readlines()[1:]\n",
    "    transactions = []\n",
    "    prev_tid = -1\n",
    "    for t in content:\n",
    "        t = t.strip().split(',')[-2:]\n",
    "        tid = t[0]\n",
    "        item = t[1]\n",
    "        if prev_tid != tid:\n",
    "            prev_tid = tid\n",
    "            transactions.append([item])\n",
    "        else:\n",
    "            transactions[-1].append(item)\n",
    "    return transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num transactions: 9531\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['Bread'],\n",
       " ['Scandinavian', 'Scandinavian'],\n",
       " ['Hot chocolate', 'Jam', 'Cookies'],\n",
       " ['Muffin'],\n",
       " ['Coffee', 'Pastry', 'Bread'],\n",
       " ['Medialuna', 'Pastry', 'Muffin'],\n",
       " ['Medialuna', 'Pastry', 'Coffee', 'Tea'],\n",
       " ['Pastry', 'Bread'],\n",
       " ['Bread', 'Muffin'],\n",
       " ['Scandinavian', 'Medialuna']]"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset('BreadBasket_DMS.csv')\n",
    "\n",
    "# ** NOTE: dataset is a 2D list (not a dataframe!) **\n",
    "\n",
    "print(\"Num transactions:\", len(dataset))\n",
    "#Print the first 10 transactions\n",
    "dataset[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q8. Data Cleaning: Many transactions in the dataset include the item \"NONE.\" First, find and remove all the \"NONE\" items from the dataset. There are some transactions that only contain \"NONE,\" so removing \"NONE\" will leave some transactions as empty lists. Remove all the empty lists as well. \n",
    "\n",
    "Once you have removed the NONEs, find the top 10 best-selling items in the bakery. Create a bar chart to display the total number of transactions for each of the top 10 selling items. Sort the bar chart by frequency (the top most sold item first, down to the 10th most sold item)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove NONEs\n",
    "\n",
    "# [:] makes a copy of dataset so we aren't skipping over values, but still modifying values in original dataset\n",
    "for transaction in dataset[:]:\n",
    "    # Remove all 'NONE's in the transaction & update in original dataset\n",
    "    transaction[:] = (item for item in transaction if item != \"NONE\")\n",
    "    \n",
    "    # If transaction is now empty, remove from original dataset\n",
    "    if len(transaction) <= 0:\n",
    "        dataset.remove(transaction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Items with Support Counts\n",
      "frozenset({'Coffee'}) , Support Counts: 4528\n",
      "frozenset({'Bread'}) , Support Counts: 3097\n",
      "frozenset({'Tea'}) , Support Counts: 1350\n",
      "frozenset({'Cake'}) , Support Counts: 983\n",
      "frozenset({'Pastry'}) , Support Counts: 815\n",
      "frozenset({'Sandwich'}) , Support Counts: 680\n",
      "frozenset({'Medialuna'}) , Support Counts: 585\n",
      "frozenset({'Hot chocolate'}) , Support Counts: 552\n",
      "frozenset({'Cookies'}) , Support Counts: 515\n",
      "frozenset({'Brownie'}) , Support Counts: 379\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 10 artists>"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1500x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from itertools import islice\n",
    "\n",
    "# Display the total number of transactions for each of the top 10 selling items\n",
    "unique_set = create_1_itemsets(dataset)\n",
    "\n",
    "retlist, support_data = filter_candidates(unique_set, dataset, 0)\n",
    "\n",
    "sorted_transac = dict(sorted(support_data.items(), key=lambda x:x[1], reverse=True))\n",
    "\n",
    "print(\"Top 10 Items with Support Counts\")\n",
    "top_10_items = []\n",
    "top_10_vals = []\n",
    "for i in islice(sorted_transac,  10):\n",
    "    print(i, \", Support Counts:\", sorted_transac.get(i))\n",
    "    top_10_items.append(list(i)[0])\n",
    "    top_10_vals.append(sorted_transac.get(i))\n",
    "    \n",
    "#create bar chart\n",
    "plt.figure(figsize=(15, 10)) \n",
    "plt.bar(top_10_items, top_10_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q9. \n",
    "\n",
    "a.) Using `mlxtend.preprocessing.TransactionEncoder`, transform `dataset` into an array format suitable for the `mlxtend` library. You will need to call `fit` then `transform`. \n",
    "\n",
    "`TransactionEncoder` learns unique items from the dataset and transforms each transaction into a one-hot encoded boolean numpy array. For example, the resulting encoded dataset will be represented by something like this, where each row is a transaction. If the first transaction contained ['Crepe', 'Jam'], this would correspond to the first row in the encoded table. \n",
    "\n",
    "<img src=\"table.png\">\n",
    "\n",
    "Print the `shape` of the resulting encoded numpy array.\n",
    "\n",
    "b.) `TransactionEncoder` also has a function `inverse_transform` that allows you to tranform one-hot encoded transactions back to the item labels. Try it out on the first 5 transactions and display the items in the first 5 transactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9465, 94)\n",
      "First 5 after inverse_transform\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['Bread'],\n",
       " ['Scandinavian'],\n",
       " ['Cookies', 'Hot chocolate', 'Jam'],\n",
       " ['Muffin'],\n",
       " ['Bread', 'Coffee', 'Pastry']]"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "te = TransactionEncoder()\n",
    "\n",
    "# Transform into array\n",
    "te_ary = te.fit(dataset).transform(dataset)\n",
    "print(te_ary.shape)\n",
    "\n",
    "# Transform back\n",
    "print(\"First 5 after inverse_transform\")\n",
    "te.inverse_transform(te_ary[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q10. Convert the encoded numpy array from Q4 part a into a pandas dataframe. Use the `TransactionEncoder`'s `.columns_` attribute as the column headers. Print the head of the resulting dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adjustment</th>\n",
       "      <th>Afternoon with the baker</th>\n",
       "      <th>Alfajores</th>\n",
       "      <th>Argentina Night</th>\n",
       "      <th>Art Tray</th>\n",
       "      <th>Bacon</th>\n",
       "      <th>Baguette</th>\n",
       "      <th>Bakewell</th>\n",
       "      <th>Bare Popcorn</th>\n",
       "      <th>Basket</th>\n",
       "      <th>...</th>\n",
       "      <th>The BART</th>\n",
       "      <th>The Nomad</th>\n",
       "      <th>Tiffin</th>\n",
       "      <th>Toast</th>\n",
       "      <th>Truffles</th>\n",
       "      <th>Tshirt</th>\n",
       "      <th>Valentine's card</th>\n",
       "      <th>Vegan Feast</th>\n",
       "      <th>Vegan mincepie</th>\n",
       "      <th>Victorian Sponge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 94 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Adjustment  Afternoon with the baker  Alfajores  Argentina Night  Art Tray  \\\n",
       "0       False                     False      False            False     False   \n",
       "1       False                     False      False            False     False   \n",
       "2       False                     False      False            False     False   \n",
       "3       False                     False      False            False     False   \n",
       "4       False                     False      False            False     False   \n",
       "\n",
       "   Bacon  Baguette  Bakewell  Bare Popcorn  Basket  ...  The BART  The Nomad  \\\n",
       "0  False     False     False         False   False  ...     False      False   \n",
       "1  False     False     False         False   False  ...     False      False   \n",
       "2  False     False     False         False   False  ...     False      False   \n",
       "3  False     False     False         False   False  ...     False      False   \n",
       "4  False     False     False         False   False  ...     False      False   \n",
       "\n",
       "   Tiffin  Toast  Truffles  Tshirt  Valentine's card  Vegan Feast  \\\n",
       "0   False  False     False   False             False        False   \n",
       "1   False  False     False   False             False        False   \n",
       "2   False  False     False   False             False        False   \n",
       "3   False  False     False   False             False        False   \n",
       "4   False  False     False   False             False        False   \n",
       "\n",
       "   Vegan mincepie  Victorian Sponge  \n",
       "0           False             False  \n",
       "1           False             False  \n",
       "2           False             False  \n",
       "3           False             False  \n",
       "4           False             False  \n",
       "\n",
       "[5 rows x 94 columns]"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q11. Use the `mlxtend.frequent_patterns.apriori` to generate the frequent itemsets with minimum support of 1% (0.01). Display these itemsets along with their support values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     support      itemsets\n",
      "0   0.036344           (2)\n",
      "1   0.016059           (6)\n",
      "2   0.327205          (11)\n",
      "3   0.040042          (14)\n",
      "4   0.103856          (15)\n",
      "..       ...           ...\n",
      "56  0.023666      (87, 23)\n",
      "57  0.014369      (73, 83)\n",
      "58  0.010037  (11, 23, 15)\n",
      "59  0.011199  (65, 11, 23)\n",
      "60  0.010037  (83, 23, 15)\n",
      "\n",
      "[61 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "df_ap = apriori(df, min_support=0.01)\n",
    "print(df_ap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q12. Use `mlxtend.frequent_patterns.fpmax` to find and display all of the maximal frequent itemsets along with their support values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>support</th>\n",
       "      <th>itemsets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.010460</td>\n",
       "      <td>(72)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.010565</td>\n",
       "      <td>(46)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.012995</td>\n",
       "      <td>(18)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.013207</td>\n",
       "      <td>(50)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.014157</td>\n",
       "      <td>(57)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.015003</td>\n",
       "      <td>(49)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.015003</td>\n",
       "      <td>(40)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.015425</td>\n",
       "      <td>(86)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.016059</td>\n",
       "      <td>(6)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.010882</td>\n",
       "      <td>(79, 23)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.019440</td>\n",
       "      <td>(25)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.020285</td>\n",
       "      <td>(88)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.029054</td>\n",
       "      <td>(74)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.023666</td>\n",
       "      <td>(87, 23)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.015848</td>\n",
       "      <td>(78, 23)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.018067</td>\n",
       "      <td>(75, 23)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.010354</td>\n",
       "      <td>(2, 11)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.019651</td>\n",
       "      <td>(2, 23)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.018806</td>\n",
       "      <td>(60, 23)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.020602</td>\n",
       "      <td>(51, 23)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.039197</td>\n",
       "      <td>(37)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.010777</td>\n",
       "      <td>(11, 14)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.019651</td>\n",
       "      <td>(14, 23)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.014474</td>\n",
       "      <td>(26, 11)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.028209</td>\n",
       "      <td>(26, 23)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.011410</td>\n",
       "      <td>(48, 15)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.013418</td>\n",
       "      <td>(48, 11)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.029583</td>\n",
       "      <td>(48, 23)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.016904</td>\n",
       "      <td>(11, 55)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.035182</td>\n",
       "      <td>(55, 23)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.014369</td>\n",
       "      <td>(73, 83)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.017010</td>\n",
       "      <td>(73, 11)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.038246</td>\n",
       "      <td>(73, 23)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.011199</td>\n",
       "      <td>(65, 11, 23)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.010037</td>\n",
       "      <td>(11, 15, 23)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.010037</td>\n",
       "      <td>(83, 15, 23)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.028104</td>\n",
       "      <td>(83, 11)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     support      itemsets\n",
       "0   0.010460          (72)\n",
       "1   0.010565          (46)\n",
       "2   0.012995          (18)\n",
       "3   0.013207          (50)\n",
       "4   0.014157          (57)\n",
       "5   0.015003          (49)\n",
       "6   0.015003          (40)\n",
       "7   0.015425          (86)\n",
       "8   0.016059           (6)\n",
       "9   0.010882      (79, 23)\n",
       "10  0.019440          (25)\n",
       "11  0.020285          (88)\n",
       "12  0.029054          (74)\n",
       "13  0.023666      (87, 23)\n",
       "14  0.015848      (78, 23)\n",
       "15  0.018067      (75, 23)\n",
       "16  0.010354       (2, 11)\n",
       "17  0.019651       (2, 23)\n",
       "18  0.018806      (60, 23)\n",
       "19  0.020602      (51, 23)\n",
       "20  0.039197          (37)\n",
       "21  0.010777      (11, 14)\n",
       "22  0.019651      (14, 23)\n",
       "23  0.014474      (26, 11)\n",
       "24  0.028209      (26, 23)\n",
       "25  0.011410      (48, 15)\n",
       "26  0.013418      (48, 11)\n",
       "27  0.029583      (48, 23)\n",
       "28  0.016904      (11, 55)\n",
       "29  0.035182      (55, 23)\n",
       "30  0.014369      (73, 83)\n",
       "31  0.017010      (73, 11)\n",
       "32  0.038246      (73, 23)\n",
       "33  0.011199  (65, 11, 23)\n",
       "34  0.010037  (11, 15, 23)\n",
       "35  0.010037  (83, 15, 23)\n",
       "36  0.028104      (83, 11)"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mlxtend.frequent_patterns import fpmax\n",
    "\n",
    "fpmax(df, min_support=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q13. Use `mlxtend.frequent_patterns.association_rules` to calculate rules with a confidence level of 0.25 for the frequent itemsets you generated in Q11."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>antecedents</th>\n",
       "      <th>consequents</th>\n",
       "      <th>antecedent support</th>\n",
       "      <th>consequent support</th>\n",
       "      <th>support</th>\n",
       "      <th>confidence</th>\n",
       "      <th>lift</th>\n",
       "      <th>leverage</th>\n",
       "      <th>conviction</th>\n",
       "      <th>zhangs_metric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(2)</td>\n",
       "      <td>(11)</td>\n",
       "      <td>0.036344</td>\n",
       "      <td>0.327205</td>\n",
       "      <td>0.010354</td>\n",
       "      <td>0.284884</td>\n",
       "      <td>0.870657</td>\n",
       "      <td>-0.001538</td>\n",
       "      <td>0.940818</td>\n",
       "      <td>-0.133570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(2)</td>\n",
       "      <td>(23)</td>\n",
       "      <td>0.036344</td>\n",
       "      <td>0.478394</td>\n",
       "      <td>0.019651</td>\n",
       "      <td>0.540698</td>\n",
       "      <td>1.130235</td>\n",
       "      <td>0.002264</td>\n",
       "      <td>1.135648</td>\n",
       "      <td>0.119574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(14)</td>\n",
       "      <td>(11)</td>\n",
       "      <td>0.040042</td>\n",
       "      <td>0.327205</td>\n",
       "      <td>0.010777</td>\n",
       "      <td>0.269129</td>\n",
       "      <td>0.822508</td>\n",
       "      <td>-0.002326</td>\n",
       "      <td>0.920538</td>\n",
       "      <td>-0.183536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(11)</td>\n",
       "      <td>(23)</td>\n",
       "      <td>0.327205</td>\n",
       "      <td>0.478394</td>\n",
       "      <td>0.090016</td>\n",
       "      <td>0.275105</td>\n",
       "      <td>0.575059</td>\n",
       "      <td>-0.066517</td>\n",
       "      <td>0.719561</td>\n",
       "      <td>-0.523431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(26)</td>\n",
       "      <td>(11)</td>\n",
       "      <td>0.054411</td>\n",
       "      <td>0.327205</td>\n",
       "      <td>0.014474</td>\n",
       "      <td>0.266019</td>\n",
       "      <td>0.813004</td>\n",
       "      <td>-0.003329</td>\n",
       "      <td>0.916638</td>\n",
       "      <td>-0.195651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(55)</td>\n",
       "      <td>(11)</td>\n",
       "      <td>0.061807</td>\n",
       "      <td>0.327205</td>\n",
       "      <td>0.016904</td>\n",
       "      <td>0.273504</td>\n",
       "      <td>0.835879</td>\n",
       "      <td>-0.003319</td>\n",
       "      <td>0.926082</td>\n",
       "      <td>-0.173062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(65)</td>\n",
       "      <td>(11)</td>\n",
       "      <td>0.086107</td>\n",
       "      <td>0.327205</td>\n",
       "      <td>0.029160</td>\n",
       "      <td>0.338650</td>\n",
       "      <td>1.034977</td>\n",
       "      <td>0.000985</td>\n",
       "      <td>1.017305</td>\n",
       "      <td>0.036980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(14)</td>\n",
       "      <td>(23)</td>\n",
       "      <td>0.040042</td>\n",
       "      <td>0.478394</td>\n",
       "      <td>0.019651</td>\n",
       "      <td>0.490765</td>\n",
       "      <td>1.025860</td>\n",
       "      <td>0.000495</td>\n",
       "      <td>1.024293</td>\n",
       "      <td>0.026259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(15)</td>\n",
       "      <td>(23)</td>\n",
       "      <td>0.103856</td>\n",
       "      <td>0.478394</td>\n",
       "      <td>0.054728</td>\n",
       "      <td>0.526958</td>\n",
       "      <td>1.101515</td>\n",
       "      <td>0.005044</td>\n",
       "      <td>1.102664</td>\n",
       "      <td>0.102840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(26)</td>\n",
       "      <td>(23)</td>\n",
       "      <td>0.054411</td>\n",
       "      <td>0.478394</td>\n",
       "      <td>0.028209</td>\n",
       "      <td>0.518447</td>\n",
       "      <td>1.083723</td>\n",
       "      <td>0.002179</td>\n",
       "      <td>1.083174</td>\n",
       "      <td>0.081700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(48)</td>\n",
       "      <td>(23)</td>\n",
       "      <td>0.058320</td>\n",
       "      <td>0.478394</td>\n",
       "      <td>0.029583</td>\n",
       "      <td>0.507246</td>\n",
       "      <td>1.060311</td>\n",
       "      <td>0.001683</td>\n",
       "      <td>1.058553</td>\n",
       "      <td>0.060403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(51)</td>\n",
       "      <td>(23)</td>\n",
       "      <td>0.038563</td>\n",
       "      <td>0.478394</td>\n",
       "      <td>0.020602</td>\n",
       "      <td>0.534247</td>\n",
       "      <td>1.116750</td>\n",
       "      <td>0.002154</td>\n",
       "      <td>1.119919</td>\n",
       "      <td>0.108738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(55)</td>\n",
       "      <td>(23)</td>\n",
       "      <td>0.061807</td>\n",
       "      <td>0.478394</td>\n",
       "      <td>0.035182</td>\n",
       "      <td>0.569231</td>\n",
       "      <td>1.189878</td>\n",
       "      <td>0.005614</td>\n",
       "      <td>1.210871</td>\n",
       "      <td>0.170091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(60)</td>\n",
       "      <td>(23)</td>\n",
       "      <td>0.038457</td>\n",
       "      <td>0.478394</td>\n",
       "      <td>0.018806</td>\n",
       "      <td>0.489011</td>\n",
       "      <td>1.022193</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>1.020777</td>\n",
       "      <td>0.022579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(65)</td>\n",
       "      <td>(23)</td>\n",
       "      <td>0.086107</td>\n",
       "      <td>0.478394</td>\n",
       "      <td>0.047544</td>\n",
       "      <td>0.552147</td>\n",
       "      <td>1.154168</td>\n",
       "      <td>0.006351</td>\n",
       "      <td>1.164682</td>\n",
       "      <td>0.146161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(73)</td>\n",
       "      <td>(23)</td>\n",
       "      <td>0.071844</td>\n",
       "      <td>0.478394</td>\n",
       "      <td>0.038246</td>\n",
       "      <td>0.532353</td>\n",
       "      <td>1.112792</td>\n",
       "      <td>0.003877</td>\n",
       "      <td>1.115384</td>\n",
       "      <td>0.109205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(75)</td>\n",
       "      <td>(23)</td>\n",
       "      <td>0.034548</td>\n",
       "      <td>0.478394</td>\n",
       "      <td>0.018067</td>\n",
       "      <td>0.522936</td>\n",
       "      <td>1.093107</td>\n",
       "      <td>0.001539</td>\n",
       "      <td>1.093366</td>\n",
       "      <td>0.088224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>(78)</td>\n",
       "      <td>(23)</td>\n",
       "      <td>0.034443</td>\n",
       "      <td>0.478394</td>\n",
       "      <td>0.015848</td>\n",
       "      <td>0.460123</td>\n",
       "      <td>0.961807</td>\n",
       "      <td>-0.000629</td>\n",
       "      <td>0.966156</td>\n",
       "      <td>-0.039502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>(79)</td>\n",
       "      <td>(23)</td>\n",
       "      <td>0.018172</td>\n",
       "      <td>0.478394</td>\n",
       "      <td>0.010882</td>\n",
       "      <td>0.598837</td>\n",
       "      <td>1.251766</td>\n",
       "      <td>0.002189</td>\n",
       "      <td>1.300235</td>\n",
       "      <td>0.204851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>(83)</td>\n",
       "      <td>(23)</td>\n",
       "      <td>0.142631</td>\n",
       "      <td>0.478394</td>\n",
       "      <td>0.049868</td>\n",
       "      <td>0.349630</td>\n",
       "      <td>0.730840</td>\n",
       "      <td>-0.018366</td>\n",
       "      <td>0.802014</td>\n",
       "      <td>-0.300482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>(87)</td>\n",
       "      <td>(23)</td>\n",
       "      <td>0.033597</td>\n",
       "      <td>0.478394</td>\n",
       "      <td>0.023666</td>\n",
       "      <td>0.704403</td>\n",
       "      <td>1.472431</td>\n",
       "      <td>0.007593</td>\n",
       "      <td>1.764582</td>\n",
       "      <td>0.332006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>(11, 15)</td>\n",
       "      <td>(23)</td>\n",
       "      <td>0.023349</td>\n",
       "      <td>0.478394</td>\n",
       "      <td>0.010037</td>\n",
       "      <td>0.429864</td>\n",
       "      <td>0.898557</td>\n",
       "      <td>-0.001133</td>\n",
       "      <td>0.914880</td>\n",
       "      <td>-0.103617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>(65, 11)</td>\n",
       "      <td>(23)</td>\n",
       "      <td>0.029160</td>\n",
       "      <td>0.478394</td>\n",
       "      <td>0.011199</td>\n",
       "      <td>0.384058</td>\n",
       "      <td>0.802807</td>\n",
       "      <td>-0.002751</td>\n",
       "      <td>0.846843</td>\n",
       "      <td>-0.201920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>(83, 15)</td>\n",
       "      <td>(23)</td>\n",
       "      <td>0.023772</td>\n",
       "      <td>0.478394</td>\n",
       "      <td>0.010037</td>\n",
       "      <td>0.422222</td>\n",
       "      <td>0.882582</td>\n",
       "      <td>-0.001335</td>\n",
       "      <td>0.902779</td>\n",
       "      <td>-0.119934</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   antecedents consequents  antecedent support  consequent support   support  \\\n",
       "0          (2)        (11)            0.036344            0.327205  0.010354   \n",
       "1          (2)        (23)            0.036344            0.478394  0.019651   \n",
       "2         (14)        (11)            0.040042            0.327205  0.010777   \n",
       "3         (11)        (23)            0.327205            0.478394  0.090016   \n",
       "4         (26)        (11)            0.054411            0.327205  0.014474   \n",
       "5         (55)        (11)            0.061807            0.327205  0.016904   \n",
       "6         (65)        (11)            0.086107            0.327205  0.029160   \n",
       "7         (14)        (23)            0.040042            0.478394  0.019651   \n",
       "8         (15)        (23)            0.103856            0.478394  0.054728   \n",
       "9         (26)        (23)            0.054411            0.478394  0.028209   \n",
       "10        (48)        (23)            0.058320            0.478394  0.029583   \n",
       "11        (51)        (23)            0.038563            0.478394  0.020602   \n",
       "12        (55)        (23)            0.061807            0.478394  0.035182   \n",
       "13        (60)        (23)            0.038457            0.478394  0.018806   \n",
       "14        (65)        (23)            0.086107            0.478394  0.047544   \n",
       "15        (73)        (23)            0.071844            0.478394  0.038246   \n",
       "16        (75)        (23)            0.034548            0.478394  0.018067   \n",
       "17        (78)        (23)            0.034443            0.478394  0.015848   \n",
       "18        (79)        (23)            0.018172            0.478394  0.010882   \n",
       "19        (83)        (23)            0.142631            0.478394  0.049868   \n",
       "20        (87)        (23)            0.033597            0.478394  0.023666   \n",
       "21    (11, 15)        (23)            0.023349            0.478394  0.010037   \n",
       "22    (65, 11)        (23)            0.029160            0.478394  0.011199   \n",
       "23    (83, 15)        (23)            0.023772            0.478394  0.010037   \n",
       "\n",
       "    confidence      lift  leverage  conviction  zhangs_metric  \n",
       "0     0.284884  0.870657 -0.001538    0.940818      -0.133570  \n",
       "1     0.540698  1.130235  0.002264    1.135648       0.119574  \n",
       "2     0.269129  0.822508 -0.002326    0.920538      -0.183536  \n",
       "3     0.275105  0.575059 -0.066517    0.719561      -0.523431  \n",
       "4     0.266019  0.813004 -0.003329    0.916638      -0.195651  \n",
       "5     0.273504  0.835879 -0.003319    0.926082      -0.173062  \n",
       "6     0.338650  1.034977  0.000985    1.017305       0.036980  \n",
       "7     0.490765  1.025860  0.000495    1.024293       0.026259  \n",
       "8     0.526958  1.101515  0.005044    1.102664       0.102840  \n",
       "9     0.518447  1.083723  0.002179    1.083174       0.081700  \n",
       "10    0.507246  1.060311  0.001683    1.058553       0.060403  \n",
       "11    0.534247  1.116750  0.002154    1.119919       0.108738  \n",
       "12    0.569231  1.189878  0.005614    1.210871       0.170091  \n",
       "13    0.489011  1.022193  0.000408    1.020777       0.022579  \n",
       "14    0.552147  1.154168  0.006351    1.164682       0.146161  \n",
       "15    0.532353  1.112792  0.003877    1.115384       0.109205  \n",
       "16    0.522936  1.093107  0.001539    1.093366       0.088224  \n",
       "17    0.460123  0.961807 -0.000629    0.966156      -0.039502  \n",
       "18    0.598837  1.251766  0.002189    1.300235       0.204851  \n",
       "19    0.349630  0.730840 -0.018366    0.802014      -0.300482  \n",
       "20    0.704403  1.472431  0.007593    1.764582       0.332006  \n",
       "21    0.429864  0.898557 -0.001133    0.914880      -0.103617  \n",
       "22    0.384058  0.802807 -0.002751    0.846843      -0.201920  \n",
       "23    0.422222  0.882582 -0.001335    0.902779      -0.119934  "
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mlxtend.frequent_patterns import association_rules\n",
    "\n",
    "association_rules(df_ap, metric=\"confidence\", min_threshold=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q14. An important step in generating a set of association rules is to determine the optimal thresholds for support and confidence. If we set these values too low we will get a lot of rules and most of them will not be useful. \n",
    "\n",
    "Generate the frequent itemsets with minimum support of 0.5% and plot the number of rules generated with respect to the confidence threshold by varying min_conf between 0 and 1 with increments of 0.1. Notice what happens when you increase the confidence level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The number of rules decreases as we increase the min confidence threshold '"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# frequent itemsets with minimum support of 0.5%\n",
    "freq = apriori(df, min_support=0.05)\n",
    "\n",
    "num_rules = []\n",
    "thresh = []\n",
    "\n",
    "for i in np.arange(0,1,0.1):\n",
    "    \n",
    "    current_rules = association_rules(freq, metric=\"confidence\", min_threshold=i)\n",
    "    num_rules.append(len(current_rules))\n",
    "    thresh.append(i)\n",
    "    \n",
    "# plot the number of rules generated\n",
    "plt.plot(thresh, num_rules)\n",
    "\n",
    "''' The number of rules decreases as we increase the min confidence threshold ''' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q15. What value would you choose for the minimum confidence threshold based on the previous plot? Explain why as a comment. \n",
    "\n",
    "Display the rules generated for the your chosen value. Take a look at the generated rules. Are they interesting? As a comment, explain why or why not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  antecedents consequents  antecedent support  consequent support   support  \\\n",
      "0        (15)        (23)            0.103856            0.478394  0.054728   \n",
      "\n",
      "   confidence      lift  leverage  conviction  zhangs_metric  \n",
      "0    0.526958  1.101515  0.005044    1.102664        0.10284  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The rule we generated may not have high support and confidence values, but their lift shows that these\\nitems have a strong implication correlation'"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' We would choose the minimum confidence threshold to be .30 because it is the highest value we can generate rules at.\n",
    "That means the items we are correlating with the purchase of others has a high correlation. So our rule is meaningful.\n",
    "'''\n",
    "\n",
    "#Display rules of 0.3 threshold\n",
    "print(association_rules(freq, metric=\"confidence\", min_threshold=0.3))\n",
    "\n",
    "'''The rule we generated may not have high support and confidence values, but their lift shows that these\n",
    "items have a strong implication correlation'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
